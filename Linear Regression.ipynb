{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Intuition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression\n",
    "This is a regression algorithm. That basically means it can be very useful to predict some continuous spectrum of output. Given an input, I want my algorithm to start predicting some output.\n",
    "\n",
    "![](images/LR1.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally what happens is, given the training data, the algorithm learns. What  doesn it learn? It learns some function, and it's going to remember function by itself, so that next time you give it a X, it predicts the Y for you using the same function that it learnt from the training data that you provided.\n",
    "\n",
    "![](images/LR2.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now what can be this function? We sometimes call it Hypothesis.\n",
    " \n",
    "![](images/LR3.png)\n",
    " \n",
    "So it's our hypothesis that this function fits the data. So what linear regression does is, it tries to put a linear function out there. Let's say we have three features x1, x2, x3 and we have an output y. Let's assume the  that y = m1x1 + m2x2 + m3x3 + b, where b is a constant term and then you are dependent on each each feature linearly. The more you are dependent on the feature, it should basically decide which feature I'm more dependent upon by varying m1 or m2 or m3and b. So the idea is, that this is the function we need to get to. To get to this function, what are you missing? You are basically missing the 4 parameters m1, m2, m3, and b. So you somehow need to learn these 4 parameters. So when you get the training data, we need to figure out a way to calculate m1, m2, m3 and b. So if you have this from your training data, whenever you want to test something,  you can just plug the values of x1, x2, x3 and you will get the output y that you are looking for.\n",
    "\n",
    "![](images/LR4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is assuming  linear relationship between x and y. So if you get data which does not have a linear relation, it's not going to perform that well, it's going to try and predict the best that it can do."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now consider and assume that the input we are given has only one x and one y. That means that we have only one feature. With one feature and one output it will be easier to plot graphs, so that's why let's only pick one input and one output, and let's see what linear regression is trying to do. Let's say my training data flows like  as shown in the image below:\n",
    "\n",
    "![](images/LR5.png)\n",
    "\n",
    "What linear regression will try and do is, it will try and fit it with one line such that it is nearest to all these points.\n",
    "\n",
    "![](images/LR6.png)\n",
    "\n",
    "The error for each individual point is the least (aim is to reduce the combined error), and the error can be defined as how far away you are from the actual value. The intuition is that we will try to find the best fit line. For example, we could have drawn another line as shown in the figure below, but it feels like this will be a bad decision because intuitively it feels that the previous line fits the data better.\n",
    "\n",
    "![](images/LR7.png)\n",
    "\n",
    "But within this, there are definitely possibilities of let's say creating this line as shown in figure below.\n",
    "\n",
    "![](images/LR8.png)\n",
    "\n",
    "Now it's not that obvious which line is better. So what linear regression is going to do is, For it will mathematically find some logic to minimise the error that we get and find the best fit line. When we are saying find the best fit line, what is it mean? For example, in two dimensions,  your equation of line is going to look like y = mx + c. So we are looking to find m and c. If you have n features, then you need to find n + 1 parameters because there is one constant value as well which is the intercept. So the eventual line will be like y = mx + c. This is slope intercept form. 'c' is the intercept and 'm' is the slope.\n",
    "\n",
    "![](images/LR9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we have learnt these parameters. How exactly will you predict for a x^ that you get for testing. We will simply calculate mx^ + c and say that this is the y that we are looking for. In case of training data, this might not give the same answer and in case of testing data, it might also not give us the right answer, but we are going to fit the best possible line and then using that line we are going to try and predict what the value of output is going to be for a specific x. So that's the basic intuition behind linear regression that let's try to find the best possible line that's going to fit our data and minimise the errors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
